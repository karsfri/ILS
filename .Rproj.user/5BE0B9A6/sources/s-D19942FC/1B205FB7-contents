---
knit: "bookdown::render_book"
title: "Prediciton Pilot"
author: "Rittman Mead"
date: "April, 2019"
site: "bookdown::bookdown_site"
output:
  bookdown::gitbook
documentclass: book
---


# Introduction

This report presents a preliminary data investigation and cleaning exercise, which resulted in several baseline models of sale events. The report outlines the processes carried out and code produced in realising a predictive model. All precursor models developed during the process and justifications for which of these were selected for further development, and which were not are also discussed.


## Assessing Model Improvements 

The models were trained and tested on separate data sets to ensure a more representative view of performance. Comparing the predictions of "Sold" or "Not Sold" produced from the model when run against the test set to the actual results determined the accuracy of the model. Here we are considering "Not Sold" to be the positive class, and "Sold" the negative class.

The output of these predictions is a confusion matrix. Confusion matrices take the form of a 2x2 matrix, where the number of correctly predicted negatives (True Negatives (TN)) are in the top left, and incorrectly predicted negatives (False Positives (FP)) are on the bottom left. The top right gives the number of incorrectly predicted negatives (False Negatives (FN)), and the bottom right the correctly predicted positives (True Positives (TP)).
From these confusion matrices other values can be found, including the sensitivity (true positive rate), specificity (true negative rate) and accuracy. 
    
$$
  Sensitivity=\frac{TP}{TP+FN}  
$$
    
$$
  Specificity=\frac{TN}{TN+FP}  
$$
    
$$
  Accuracy=\frac{TN+TP}{TN+TP+FN+FP}  
$$
    
$$
  F-value=\frac{2TP}{2TP+FP+FN}  
$$


If we wanted a model to maximize the number of correctly predicted "Not Sold" events we could quantify improvements in the predictive ability of the model by larger sensitivity. We could then train our model to correctly predict more "Not Sold" events at the expense of other metrics such as accuracy. (Some examples of this will be shown later.)

